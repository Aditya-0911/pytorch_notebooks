{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMQmbKg3HIR8",
        "outputId": "820ab3b2-eeef-4547-e040-87d03465c01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (70000, 784), Labels shape: (70000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load Fashion MNIST\n",
        "fashion_mnist = fetch_openml('Fashion-MNIST', version=1, as_frame=False)\n",
        "\n",
        "# Extract data and labels\n",
        "X, y = fashion_mnist.data, fashion_mnist.target.astype(int)\n",
        "\n",
        "print(f\"Data shape: {X.shape}, Labels shape: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jSQ7Q-9mHRWZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsHuK_KxHSkY",
        "outputId": "e737bb4f-9668-484d-e94f-a1c4b21e0413"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78fa6080c070>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSxeCeFBHUDV",
        "outputId": "9969aa7a-2290-4498-ebcd-1d94b73cf23c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "02Wi1inGHVf2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "\n",
        "    self.x = torch.tensor(x, dtype=torch.float32)\n",
        "    self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "TLgX3I4zHevf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset(x_train, y_train)\n",
        "test_dataset = dataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "ZrgQaWXeHgEt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=128,pin_memory=True, shuffle=True) # use larger batch size and pin_memory\n",
        "test_loader = DataLoader(test_dataset, batch_size=128,pin_memory=True, shuffle=True)"
      ],
      "metadata": {
        "id": "PwtHPA1XHhRI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self,num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(64, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "wVzl1PWpHieB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 25\n",
        "\n",
        "model = Model(x_train.shape[1]).to(device)\n",
        "\n",
        "lossfn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "wk2k7xn9H702"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "\n",
        "    loss = lossfn(output, batch_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch: {i+1}, Loss: {total_epoch_loss/len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-9dyIX6IgHG",
        "outputId": "e6ffbb47-faff-46ef-a0bf-e76eaa74390a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.6077312286858145\n",
            "Epoch: 2, Loss: 0.41324491455266466\n",
            "Epoch: 3, Loss: 0.3772756142975533\n",
            "Epoch: 4, Loss: 0.3523756817459516\n",
            "Epoch: 5, Loss: 0.33589363635675\n",
            "Epoch: 6, Loss: 0.3202941038701088\n",
            "Epoch: 7, Loss: 0.3077953222407598\n",
            "Epoch: 8, Loss: 0.29657483168932947\n",
            "Epoch: 9, Loss: 0.2933017376419072\n",
            "Epoch: 10, Loss: 0.28408449684103876\n",
            "Epoch: 11, Loss: 0.2751291892810227\n",
            "Epoch: 12, Loss: 0.2697585779986425\n",
            "Epoch: 13, Loss: 0.26223567910662526\n",
            "Epoch: 14, Loss: 0.25653306527497016\n",
            "Epoch: 15, Loss: 0.2501318236328151\n",
            "Epoch: 16, Loss: 0.24648611196508147\n",
            "Epoch: 17, Loss: 0.24011652814607098\n",
            "Epoch: 18, Loss: 0.2339192908512403\n",
            "Epoch: 19, Loss: 0.2306138962405185\n",
            "Epoch: 20, Loss: 0.22895447248125186\n",
            "Epoch: 21, Loss: 0.22401543172527122\n",
            "Epoch: 22, Loss: 0.2206952725473332\n",
            "Epoch: 23, Loss: 0.22065545712091608\n",
            "Epoch: 24, Loss: 0.21330938409996902\n",
            "Epoch: 25, Loss: 0.213516608833178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IAf1l6LIn3g",
        "outputId": "cb19481a-468b-4e2f-d53c-3db0549d2b9d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.2, inplace=False)\n",
              "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "    total += batch_labels.size(0)\n",
        "\n",
        "    count += (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {count/total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1v_Bwi5Ip6l",
        "outputId": "cab78544-9068-4309-8c2d-518b731b77c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9012142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "    total += batch_labels.size(0)\n",
        "\n",
        "    count += (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {count/total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBUUDr7dIrTh",
        "outputId": "c91e6fe4-7275-46f6-a7b8-536cd8ae81de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9453928571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nm7sIO37Iu7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}